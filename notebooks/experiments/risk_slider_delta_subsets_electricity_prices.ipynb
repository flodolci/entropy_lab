{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "201452b1",
   "metadata": {},
   "source": [
    "# Risk-Aware Compression of Electricity Prices with $\\delta$-Subsets\n",
    "\n",
    "We will run a little experiment to display the meaning of the $\\delta$-subset for lossy compression. Roughly, we will follow these steps: Electricity prices --> discretize into bins --> build an alphabet distribution --> compute entropy --> $\\delta$-subset --> visualization of kept versus dropped. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2204800",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "We will treat binned electricity prices as an \"alphabet\" of symbols. Each symbol is a price range (e.g. $\\left[50, 55\\right)$ CHF/MWh). The probability of a symbol is the fraction of hours in that range. Then, for a chosen risk budget $\\delta$, we compute the smallest set of bins whose total probability mass is at least $1-\\delta$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f289aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from entropy_lab.coding.alphabet import AlphabetDistribution\n",
    "from entropy_lab.measures.entropy import compute_entropy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c4ef8a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2f45d8db",
   "metadata": {},
   "source": [
    "## Loading the daily price data\n",
    "\n",
    "Electricity prices have a \"boring bulk\" (most hours) and a \"long tail\" (rare spikes). That long tail is exactly where $\\delta$-subsets are intuitive: How much tail mass are we willing to ignore for a simpler model/encoding?\n",
    "\n",
    "For this example, we will use Switzerland's wholesale hourly electricity prices. Let us load the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab4e91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/Users/fdolci/projects/entropy_lab/data/Switzerland.csv\")\n",
    "prices = df[\"Price (EUR/MWhe)\"].to_numpy()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f147324f",
   "metadata": {},
   "source": [
    "## Discretization\n",
    "\n",
    "Now that we have a dataset which include all the prices, we will discretize these prices into bins. This will define the alphabet of symbols:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8b92f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_width = 5.0 # EUR/MWhe\n",
    "lo = np.floor(prices.min() / bin_width) * bin_width\n",
    "hi = np.ceil(prices.max() / bin_width) * bin_width\n",
    "edges = np.arange(lo, hi + bin_width, bin_width)\n",
    "\n",
    "# Bin index for each price\n",
    "idx = np.digitize(prices, edges) - 1\n",
    "idx = np.clip(idx, 0, len(edges) - 2)\n",
    "\n",
    "# Convert each bin to a readable symbol label\n",
    "def bin_label(i: int) -> str:\n",
    "    a = edges[i]\n",
    "    b = edges[i + 1]\n",
    "    return f\"[{a:.0f},{b:.0f})\"\n",
    "\n",
    "symbols = [bin_label(i) for i in idx]\n",
    "\n",
    "# Count symbols\n",
    "counts = {}\n",
    "for s in symbols:\n",
    "    counts[s] = counts.get(s, 0) + 1\n",
    "\n",
    "dist = AlphabetDistribution.from_counts(counts).ranked()\n",
    "len(dist.symbols), dist.symbols[:5], dist.p[:5].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b90697",
   "metadata": {},
   "source": [
    "Now we have a discrete distribution over price-bins. The most probable bins correspond to \"normal market conditions\". The least probable bins are rare spikes or rare negative prices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e67522",
   "metadata": {},
   "source": [
    "## Entropy of the price-bin distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b361a771",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = dist.p \n",
    "H = compute_entropy(p)\n",
    "H"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5de6f44",
   "metadata": {},
   "source": [
    "As explained in the theory, entropy measures the average suprise of the price-bin outcome. A distribution with many similarly-likely bins has higher entropy than one dominated by a few bins."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37aed0fd",
   "metadata": {},
   "source": [
    "## Visualization of the full distribution (ranked by probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18477250",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n = min(30, len(dist.symbols))\n",
    "x = np.arange(top_n)\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.bar(x, dist.p[:top_n])\n",
    "plt.xticks(x, dist.symbols[:top_n], rotation=70, ha=\"right\")\n",
    "plt.ylabel(\"Probability (share of hours)\")\n",
    "plt.title(f\"Top {top_n} price bins by frequency (Entropy = {H:.2f} bits)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a17f6e",
   "metadata": {},
   "source": [
    "This ranked plot is the visual \"alphabet\": The left side is your everyday market, the right side is the long tail. We will now compute the $\\delta$-subset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a757737d",
   "metadata": {},
   "source": [
    "## $\\delta$-subset\n",
    "\n",
    "This means that, for a given risk level $\\delta$, we will keep the $1-\\delta$ mass, and therefore drop the tail:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a6d90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = 0.05 # we accept 5% risk of landing in dropped bins\n",
    "res = dist.delta_subset(delta)\n",
    "\n",
    "res.threshold, res.kept_probability, res.dropped_probability, len(res.kept.symbols), len(res.dropped_symbols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e52d83f",
   "metadata": {},
   "source": [
    "Interpretation: With $\\delta = 0.05$, we build the smallest set of bins that cover at least $95\\%$ of observed hours. The dropped bins represent \"rare regimes\" (e.g., spikes). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc4e160",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17a8e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranked = dist  # already ranked\n",
    "p_ranked = ranked.p\n",
    "labels_ranked = ranked.symbols\n",
    "\n",
    "k = len(res.kept.symbols)\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "x = np.arange(len(p_ranked))\n",
    "plt.bar(x[:k], p_ranked[:k], label=f\"Kept bins (mass ≈ {res.kept_probability:.3f})\")\n",
    "plt.bar(x[k:], p_ranked[k:], label=f\"Dropped bins (mass ≈ {res.dropped_probability:.3f})\")\n",
    "plt.axvline(k - 0.5)\n",
    "plt.ylabel(\"Probability\")\n",
    "plt.title(f\"δ-subset on price bins (δ={delta:.2f} → keep ≥ {1-delta:.2f} mass) | kept bins = {k}/{len(p_ranked)}\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bfaebfd",
   "metadata": {},
   "source": [
    "If $\\delta$ increases (we accept more risk), we can observe the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d7ae0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "deltas = np.linspace(0.0, 0.25, 26)  # 0% to 25% tail risk\n",
    "kept_sizes = []\n",
    "kept_mass = []\n",
    "H_kept = []\n",
    "\n",
    "for d in deltas:\n",
    "    r = dist.delta_subset(float(d))\n",
    "    kept_sizes.append(len(r.kept.symbols))\n",
    "    kept_mass.append(r.kept_probability)\n",
    "    H_kept.append(compute_entropy(r.kept.p))\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(deltas, kept_sizes, marker=\"o\")\n",
    "plt.xlabel(\"δ (risk budget)\")\n",
    "plt.ylabel(\"Kept alphabet size |Aδ| (number of bins)\")\n",
    "plt.title(\"As we allow more risk δ, the required price alphabet shrinks\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881f804a",
   "metadata": {},
   "source": [
    "## Comparing with Germany"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6b16d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_de = pd.read_csv(\"/Users/fdolci/projects/entropy_lab/data/Germany.csv\")\n",
    "prices_de = df_de[\"Price (EUR/MWhe)\"].to_numpy()\n",
    "\n",
    "# For a fair comparison, use ONE shared set of bin edges\n",
    "all_prices = np.concatenate([prices, prices_de])\n",
    "\n",
    "bin_width = 5.0\n",
    "lo = np.floor(all_prices.min() / bin_width) * bin_width\n",
    "hi = np.ceil(all_prices.max() / bin_width) * bin_width\n",
    "edges = np.arange(lo, hi + bin_width, bin_width)\n",
    "\n",
    "def prices_to_dist(prices_arr: np.ndarray, edges: np.ndarray) -> AlphabetDistribution:\n",
    "    idx = np.digitize(prices_arr, edges) - 1\n",
    "    idx = np.clip(idx, 0, len(edges) - 2)\n",
    "\n",
    "    def bin_label(i: int) -> str:\n",
    "        a = edges[i]\n",
    "        b = edges[i + 1]\n",
    "        return f\"[{a:.0f},{b:.0f})\"\n",
    "\n",
    "    symbols = [bin_label(i) for i in idx]\n",
    "\n",
    "    counts = {}\n",
    "    for s in symbols:\n",
    "        counts[s] = counts.get(s, 0) + 1\n",
    "\n",
    "    return AlphabetDistribution.from_counts(counts).ranked()\n",
    "\n",
    "dist_ch = prices_to_dist(prices, edges)\n",
    "dist_de = prices_to_dist(prices_de, edges)\n",
    "\n",
    "H_ch = compute_entropy(dist_ch.p)\n",
    "H_de = compute_entropy(dist_de.p)\n",
    "\n",
    "len(dist_ch.symbols), len(dist_de.symbols), H_ch, H_de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940fce5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = 0.05\n",
    "\n",
    "res_ch = dist_ch.delta_subset(delta)\n",
    "res_de = dist_de.delta_subset(delta)\n",
    "\n",
    "print(\"CH kept mass / bins:\", res_ch.kept_probability, len(res_ch.kept.symbols), \"of\", len(dist_ch.symbols))\n",
    "print(\"GER kept mass / bins:\", res_de.kept_probability, len(res_de.kept.symbols), \"of\", len(dist_de.symbols))\n",
    "\n",
    "H_ch_kept = compute_entropy(res_ch.kept.p)\n",
    "H_de_kept = compute_entropy(res_de.kept.p)\n",
    "\n",
    "print(\"Entropy full CH / kept:\", H_ch, H_ch_kept)\n",
    "print(\"Entropy full GER / kept:\", H_de, H_de_kept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ad1560",
   "metadata": {},
   "outputs": [],
   "source": [
    "deltas = np.linspace(0.0, 0.25, 26)\n",
    "\n",
    "def compression_profile(dist: AlphabetDistribution, deltas: np.ndarray):\n",
    "    kept_sizes = []\n",
    "    kept_mass = []\n",
    "    kept_entropy = []\n",
    "    for d in deltas:\n",
    "        r = dist.delta_subset(float(d))\n",
    "        kept_sizes.append(len(r.kept.symbols))\n",
    "        kept_mass.append(r.kept_probability)\n",
    "        kept_entropy.append(compute_entropy(r.kept.p))\n",
    "    return np.array(kept_sizes), np.array(kept_mass), np.array(kept_entropy)\n",
    "\n",
    "sizes_ch, mass_ch, Hk_ch = compression_profile(dist_ch, deltas)\n",
    "sizes_de, mass_de, Hk_de = compression_profile(dist_de, deltas)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot(deltas, sizes_ch, marker=\"o\", label=f\"Switzerland | H={H_ch:.2f} bits\")\n",
    "plt.plot(deltas, sizes_de, marker=\"o\", label=f\"Germany      | H={H_de:.2f} bits\")\n",
    "\n",
    "# Highlight the chosen delta\n",
    "plt.axvline(delta, linestyle=\"--\")\n",
    "plt.scatter([delta], [len(res_ch.kept.symbols)], s=80)\n",
    "plt.scatter([delta], [len(res_de.kept.symbols)], s=80)\n",
    "\n",
    "plt.xlabel(\"δ (risk budget: probability mass you allow to drop)\")\n",
    "plt.ylabel(\"Kept alphabet size |Aδ| (number of price bins)\")\n",
    "plt.title(\"Risk-aware lossy compression of electricity prices: CH vs GER\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "entropy_lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
