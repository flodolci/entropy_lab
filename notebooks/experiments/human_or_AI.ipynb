{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1588ff7",
   "metadata": {},
   "source": [
    "# Entropy Labs - Human versus AI text\n",
    "\n",
    "The Shannon information content and entropy measures lead us to a natural question: What can we use them for? One possibility would be to differentiated different regimes: For instance, different price regimes in an electricity price time series, or different seasonal patterns in a windmill production record.\n",
    "\n",
    "One other example, which will be the topic of this notebook, is to differentiate different types of texts: Could we use these metrics to differentiate human-generated versus AI-generated text? I do not know, but let's try to find this out!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0724734",
   "metadata": {},
   "source": [
    "Let us start by importing the necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb1c534",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import math\n",
    "from collections import Counter\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "from entropy_lab.measures.shannon import shannon_information\n",
    "from entropy_lab.measures.entropy import compute_entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74251aca",
   "metadata": {},
   "source": [
    "## Text Preprocessing and tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8072ee6f",
   "metadata": {},
   "source": [
    "There are different ways to tokenize a text, but we will here create a simple function to do so. The function will take a text as a string as input, and split each words, as well as remove the numbers, to return a list of words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a630b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import unicodedata\n",
    "from typing import List\n",
    "\n",
    "def preprocess_text(text: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Improved tokenizer for stylometric / entropy analysis.\n",
    "\n",
    "    What it does:\n",
    "    - Unicode normalization (curly quotes -> regular forms, etc.)\n",
    "    - Lowercase\n",
    "    - Replace numbers with <num> (including decimals / percentages)\n",
    "    - Keep words (including apostrophes and hyphens)\n",
    "    - Keep punctuation as separate tokens (useful for style)\n",
    "    - Keeps accented characters (French/German/Italian friendly)\n",
    "\n",
    "    Examples:\n",
    "    \"Don't pay 12.5% now!\" -> [\"don't\", \"pay\", \"<num>\", \"%\", \"now\", \"!\"]\n",
    "    \"state-of-the-art\"      -> [\"state-of-the-art\"]\n",
    "    \"\"\"\n",
    "    # Normalize Unicode (helps standardize quotes/dashes)\n",
    "    text = unicodedata.normalize(\"NFKC\", text)\n",
    "\n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # Standardize some common punctuation variants\n",
    "    text = text.replace(\"“\", '\"').replace(\"”\", '\"')\n",
    "    text = text.replace(\"‘\", \"'\").replace(\"’\", \"'\")\n",
    "    text = text.replace(\"—\", \"-\").replace(\"–\", \"-\")\n",
    "\n",
    "    # Replace numbers (integers, decimals, commas) with <num>\n",
    "    # Examples: 12, 12.5, 1,000, 3.1415\n",
    "    text = re.sub(r\"\\b\\d+(?:[.,]\\d+)*\\b\", \" <num> \", text)\n",
    "\n",
    "    # Token pattern:\n",
    "    # - <num>\n",
    "    # - words with internal apostrophes/hyphens (e.g., don't, state-of-the-art)\n",
    "    # - punctuation as separate tokens\n",
    "    token_pattern = r\"\"\"\n",
    "        <num>\n",
    "        |\n",
    "        [^\\W\\d_]+(?:[-'][^\\W\\d_]+)*   # Unicode letters, optional internal - or '\n",
    "        |\n",
    "        [.,!?;:%()\"'/\\-]              # punctuation tokens kept separately\n",
    "    \"\"\"\n",
    "\n",
    "    tokens = re.findall(token_pattern, text, flags=re.VERBOSE | re.UNICODE)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b5b042",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_text = \"A car is driving at 25 kmh! What a car!\"\n",
    "example_tokens = preprocess_text(example_text)\n",
    "example_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58edd238",
   "metadata": {},
   "source": [
    "## Human Reference Distribution with Smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba8aa2c",
   "metadata": {},
   "source": [
    "To be able to compare a text agains another, we need a reference, i.e., a baseline. This reference distribution will define what \"normal\" word usage looks like. This is needed, as we want to have a far comparison by using the same human reference for both the human text and the AI-generated text.\n",
    "\n",
    "The role of the smoothing is to still provide with a non-existing word a nonzero probability. This is to avoid non-defined behaviours when computing the Shannon Information content. To do this, we will use the Laplace smoothing function:\n",
    "\n",
    "$$p\\left(\\mathrm{word}\\right) = \\frac{\\mathrm{count}\\left(\\mathrm{word}\\right) + \\alpha}{N + \\alpha\\left(V+1\\right)}$$\n",
    "\n",
    "with \n",
    "* $N$: Total tokens in reference corpus\n",
    "* $V$: Number of unique words in reference corpus\n",
    "* $\\alpha$: Smoothing strength\n",
    "* $+1$: One extra \"unknown word\" bucket\n",
    "\n",
    "We can compute this using the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d592636",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReferenceLanguageModel:\n",
    "    \"\"\"\n",
    "    Simple reference model: p(word) estimated from a reference corpus (human text).\n",
    "\n",
    "    We use Laplace smoothing:\n",
    "        p(w) = (count(w) + alpha) / (N + alpha*(V+1))\n",
    "    \n",
    "    where:\n",
    "        N = total tokens in reference corpus\n",
    "        V = vocabulary size in reference corpus\n",
    "        +1 = reserve one \"unknown bucket\"    \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, reference_tokens: List[str], alpha: float = 1.0):\n",
    "        if len(reference_tokens) == 0:\n",
    "            raise ValueError(\"Reference token list is empty.\")\n",
    "        self.alpha = float(alpha)\n",
    "        self.counts = Counter(reference_tokens)\n",
    "        self.N = sum(self.counts.values())\n",
    "        self.V = len(self.counts)\n",
    "\n",
    "    def p(self, token: str) -> float:\n",
    "        count_w = self.counts.get(token, 0)\n",
    "        numerator = count_w + self.alpha\n",
    "        denominator = self.N + self.alpha * (self.V + 1)\n",
    "        return numerator / denominator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc557d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference = ReferenceLanguageModel(example_tokens)\n",
    "reference.alpha, reference.counts, reference.N, reference.V, reference.p('car')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca47664e",
   "metadata": {},
   "source": [
    "## Surprisal of a Text\n",
    "\n",
    "We now have a way to compute the reference distribution for a given text. Can we now compute the Shannon Information content (aka surprisal) for a given text? Using the custom-made ```shannon_information``` function, nothing is easier: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8167ea0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from entropy_lab.measures.shannon import shannon_information\n",
    "\n",
    "def score_text_with_reference(\n",
    "        text: str,\n",
    "        ref_model: ReferenceLanguageModel,\n",
    "        base: float = 2.0\n",
    ") -> Tuple[List[str], np.ndarray, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    For each token in 'text':\n",
    "        - compute p_ref(token)\n",
    "        - compute surprisal h(token) = -log_base(p_ref(token))\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tokens: list[str]\n",
    "    surprisals: np.ndarray\n",
    "    token_df: pd.DataFrame with columns [token, p_ref, surprisal_bits]\n",
    "    \"\"\"\n",
    "    tokens = preprocess_text(text)\n",
    "    rows = []\n",
    "    surprisals = []\n",
    "    for tok in tokens:\n",
    "        p_ref = ref_model.p(tok)\n",
    "        h = shannon_information(p_ref, base=base)\n",
    "        surprisals.append(h)\n",
    "        rows.append({\n",
    "            \"token\": tok,\n",
    "            \"p_ref\": p_ref,\n",
    "            \"surprisal_bits\": h\n",
    "        })\n",
    "    token_df = pd.DataFrame(rows)\n",
    "    return tokens, np.array(surprisals, dtype=float), token_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff25d95",
   "metadata": {},
   "source": [
    "To display the functionality of this function, let us a use a slightly longer text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f7a6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ww2_human_text = \"The causes of World War II included unresolved tensions in the aftermath of World War I, and the rise of fascism in Europe and militarism in Japan. Key events preceding the war included Japan's invasion of Manchuria in 1931, the Spanish Civil War, the outbreak of the Second Sino-Japanese War in 1937, and Germany's annexations of Austria and the Sudetenland. World War II is generally considered to have begun on 1 September 1939, when Nazi Germany, under Adolf Hitler, invaded Poland, after which the United Kingdom and France declared war on Germany. Poland was also invaded by the Soviet Union in mid-September, and was partitioned between Germany and the Soviet Union under the Molotov–Ribbentrop Pact. In 1940, the Soviet Union annexed the Baltic states and parts of Finland and Romania, while Germany conquered Norway, Belgium, Luxembourg, and the Netherlands. After the fall of France in June 1940, the war continued mainly between Germany, now assisted by Fascist Italy, and the British Empire/British Commonwealth, with fighting in the Balkans, Mediterranean, and Middle East, East Africa, the aerial Battle of Britain and the Blitz, and the naval Battle of the Atlantic. By mid-1941, Yugoslavia and Greece had also been defeated by Axis countries. In June 1941, Germany invaded the Soviet Union, opening the Eastern Front and initially making large territorial gains along with Axis allies.\"\n",
    "\n",
    "ww2_ai_text = \"World War II emerged from a 'perfect storm' of geopolitical resentment and economic instability that had been brewing since the end of the Great War. The Treaty of Versailles left Germany economically crippled and deeply humiliated, creating a power vacuum that Adolf Hitler filled with promises of national restoration and territorial expansion. This instability was exacerbated by the Great Depression, which destabilized global markets and led many nations to turn toward radical, totalitarian leadership in search of security. As Japan sought resources through the invasion of China and Italy pursued African conquests, the international community’s policy of appeasement failed to check these aggressions, ultimately signaling to the Axis powers that they could expand without consequence. The tension finally reached a breaking point on September 1, 1939, when Germany's invasion of Poland forced the Allied powers to abandon diplomacy, launching the most destructive conflict in human history.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40bbecbd",
   "metadata": {},
   "source": [
    "We first start by building the reference model using ```ww2_human_text``` and scoring on the AI text ```www2_ai_text```. Of course, we would need a third text to then compare, but this is just for illustrative purposes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d362295d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_text = ww2_human_text\n",
    "ref_tokens = preprocess_text(ref_text)\n",
    "ref_model = ReferenceLanguageModel(ref_tokens, alpha=1.0)\n",
    "test_text = ww2_ai_text\n",
    "tokens, surprisals, df = score_text_with_reference(test_text, ref_model)\n",
    "print(df)\n",
    "print(\"Mean surprisal:\", surprisals.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7b3a53",
   "metadata": {},
   "source": [
    "## Summary Statistics\n",
    "\n",
    "We create a summary statistics function to compare both texts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4510b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_surprisal(tokens: List[str], surprisals: np.ndarray) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Summary stats to compare texts.\n",
    "    \"\"\"\n",
    "    if len(tokens) == 0:\n",
    "        raise ValueError(\"No tokens to summarize.\")\n",
    "    n_tokens = len(tokens)\n",
    "    n_unique = len(set(tokens))\n",
    "    type_token_ratio = n_unique / n_tokens\n",
    "    summary = pd.Series({\n",
    "        \"n_tokens\": n_tokens,\n",
    "        \"n_unique\": n_unique,\n",
    "        \"type_token_ratio\": type_token_ratio,\n",
    "        \"mean_surprisal_bits\": float(np.mean(surprisals)),\n",
    "        \"median_surprisal_bits\": float(np.median(surprisals)),\n",
    "        \"std_surprisal_bits\": float(np.std(surprisals)),\n",
    "        \"frac_surprisal_gt_8\": float(np.mean(surprisals > 8)),\n",
    "        \"frac_surprisal_gt_10\": float(np.mean(surprisals > 10))\n",
    "    })\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31163a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize_surprisal(tokens, surprisals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1232a0",
   "metadata": {},
   "source": [
    "## Entropy Table\n",
    "\n",
    "We now will write down a function to generate a table displaying each token, its count, its probability, it's surprisal, and returning as well the total empirical Shannon entropy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0a0039",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_entropy_table(tokens: List[str], base: float = 2.0) -> Tuple[pd.DataFrame, float]:\n",
    "    \"\"\"\n",
    "    Build a table:\n",
    "        token | count | p_i | h(p_i) | p_i * h(p_i)\n",
    "\n",
    "    using the empirical distribution of the given token list.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    entropy_table: pd.DataFrame\n",
    "    H: float (empirical Shannon entropy in bits/token)\n",
    "    \"\"\"\n",
    "    counts = Counter(tokens)\n",
    "    N = sum(counts.values())\n",
    "    rows = []\n",
    "    for token, c in counts.items():\n",
    "        p_i = c / N\n",
    "        h_i = shannon_information(p_i, base=base)\n",
    "        contrib = p_i * h_i \n",
    "        rows.append({\n",
    "            \"token\": token,\n",
    "            \"count\": c,\n",
    "            \"p_i\": p_i,\n",
    "            \"h(p_i)_bits\": h_i,\n",
    "            \"p_i*h(p_i)\": contrib\n",
    "        })\n",
    "    df = pd.DataFrame(rows)\n",
    "    df = df.sort_values(\"count\", ascending=False).reset_index(drop=True)\n",
    "    H = float(df[\"p_i*h(p_i)\"].sum())\n",
    "    return df, H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762e5a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "build_entropy_table(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6acfefd",
   "metadata": {},
   "source": [
    "# Helper Functions for Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e91466",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Optional, Dict\n",
    "\n",
    "\n",
    "def rolling_mean(values: np.ndarray, window: int = 30) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Simple rolling mean of a 1D array.\n",
    "    \"\"\"\n",
    "    values = np.asarray(values, dtype=float)\n",
    "    if window <= 1:\n",
    "        return values.copy()\n",
    "\n",
    "    out = np.empty_like(values, dtype=float)\n",
    "    for i in range(len(values)):\n",
    "        start = max(0, i - window + 1)\n",
    "        out[i] = np.mean(values[start:i + 1])\n",
    "    return out\n",
    "\n",
    "\n",
    "def rolling_quantile(values: np.ndarray, window: int = 30, q: float = 0.5) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Rolling quantile of a 1D array.\n",
    "    \"\"\"\n",
    "    values = np.asarray(values, dtype=float)\n",
    "    if not (0.0 <= q <= 1.0):\n",
    "        raise ValueError(\"q must be between 0 and 1.\")\n",
    "\n",
    "    out = np.empty_like(values, dtype=float)\n",
    "    for i in range(len(values)):\n",
    "        start = max(0, i - window + 1)\n",
    "        out[i] = np.quantile(values[start:i + 1], q)\n",
    "    return out\n",
    "\n",
    "\n",
    "def summarize_surprisal_array(values: np.ndarray) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Compact summary stats for a surprisal array.\n",
    "    \"\"\"\n",
    "    v = np.asarray(values, dtype=float)\n",
    "    v = v[np.isfinite(v)]\n",
    "    if len(v) == 0:\n",
    "        return {\n",
    "            \"mean\": np.nan,\n",
    "            \"std\": np.nan,\n",
    "            \"median\": np.nan,\n",
    "            \"p10\": np.nan,\n",
    "            \"p90\": np.nan,\n",
    "            \"n\": 0,\n",
    "        }\n",
    "\n",
    "    return {\n",
    "        \"mean\": float(np.mean(v)),\n",
    "        \"std\": float(np.std(v, ddof=0)),\n",
    "        \"median\": float(np.median(v)),\n",
    "        \"p10\": float(np.quantile(v, 0.10)),\n",
    "        \"p90\": float(np.quantile(v, 0.90)),\n",
    "        \"n\": int(len(v)),\n",
    "    }\n",
    "\n",
    "\n",
    "def plot_rolling_surprisal(\n",
    "    human_surprisal: np.ndarray,\n",
    "    ai_surprisal: np.ndarray,\n",
    "    window: int = 30,\n",
    "    show_raw: bool = False,\n",
    "    human_oov_rate: Optional[float] = None,\n",
    "    ai_oov_rate: Optional[float] = None,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Cleaner comparison plot:\n",
    "      - rolling mean lines\n",
    "      - rolling 10-90% quantile bands\n",
    "      - optional faint raw lines\n",
    "      - summary stats box\n",
    "\n",
    "    Notes:\n",
    "      - x-axis is token index within each text (not semantic alignment)\n",
    "      - mean surprisal ~= cross-entropy estimate under the reference model\n",
    "    \"\"\"\n",
    "    human_surprisal = np.asarray(human_surprisal, dtype=float)\n",
    "    ai_surprisal = np.asarray(ai_surprisal, dtype=float)\n",
    "\n",
    "    # Rolling center\n",
    "    human_roll = rolling_mean(human_surprisal, window=window)\n",
    "    ai_roll = rolling_mean(ai_surprisal, window=window)\n",
    "\n",
    "    # Rolling uncertainty bands (local variability)\n",
    "    human_q10 = rolling_quantile(human_surprisal, window=window, q=0.10)\n",
    "    human_q90 = rolling_quantile(human_surprisal, window=window, q=0.90)\n",
    "    ai_q10 = rolling_quantile(ai_surprisal, window=window, q=0.10)\n",
    "    ai_q90 = rolling_quantile(ai_surprisal, window=window, q=0.90)\n",
    "\n",
    "    # Summary stats\n",
    "    hs = summarize_surprisal_array(human_surprisal)\n",
    "    ais = summarize_surprisal_array(ai_surprisal)\n",
    "    delta_mean = ais[\"mean\"] - hs[\"mean\"]\n",
    "\n",
    "    # Figure with 2 rows: main plot + stats panel\n",
    "    fig = plt.figure(figsize=(12, 7), dpi=140)\n",
    "    gs = fig.add_gridspec(nrows=2, ncols=1, height_ratios=[4.5, 1.4], hspace=0.15)\n",
    "\n",
    "    ax = fig.add_subplot(gs[0])\n",
    "\n",
    "    # Optional raw series (very faint)\n",
    "    if show_raw:\n",
    "        ax.plot(human_surprisal, alpha=0.10, linewidth=0.8, label=\"Human (raw)\")\n",
    "        ax.plot(ai_surprisal, alpha=0.10, linewidth=0.8, label=\"AI (raw)\")\n",
    "\n",
    "    # Bands first (so lines stay visible)\n",
    "    xh = np.arange(len(human_surprisal))\n",
    "    xa = np.arange(len(ai_surprisal))\n",
    "    ax.fill_between(xh, human_q10, human_q90, alpha=0.18, label=f\"Human (rolling {window} q10–q90)\")\n",
    "    ax.fill_between(xa, ai_q10, ai_q90, alpha=0.18, label=f\"AI (rolling {window} q10–q90)\")\n",
    "\n",
    "    # Rolling means\n",
    "    ax.plot(human_roll, linewidth=2.2, label=f\"Human (rolling mean {window})\")\n",
    "    ax.plot(ai_roll, linewidth=2.2, label=f\"AI (rolling mean {window})\")\n",
    "\n",
    "    ax.set_xlabel(\"Token index\")\n",
    "    ax.set_ylabel(\"Surprisal (bits)\")\n",
    "    ax.set_title(\"Word-level surprisal under human reference corpus\")\n",
    "    ax.grid(alpha=0.25)\n",
    "    ax.legend(loc=\"upper right\", frameon=True)\n",
    "\n",
    "    # Stats panel\n",
    "    ax_stats = fig.add_subplot(gs[1])\n",
    "    ax_stats.axis(\"off\")\n",
    "\n",
    "    # Build compact text block\n",
    "    lines = [\n",
    "        f\"Human: mean={hs['mean']:.3f} bits, median={hs['median']:.3f}, std={hs['std']:.3f}, p90={hs['p90']:.3f}, n={hs['n']}\",\n",
    "        f\"AI:    mean={ais['mean']:.3f} bits, median={ais['median']:.3f}, std={ais['std']:.3f}, p90={ais['p90']:.3f}, n={ais['n']}\",\n",
    "        f\"Δ mean (AI - Human) = {delta_mean:.3f} bits/token\",\n",
    "    ]\n",
    "    if human_oov_rate is not None and ai_oov_rate is not None:\n",
    "        lines.append(\n",
    "            f\"OOV rate (under reference, pre-smoothing): Human={100*human_oov_rate:.2f}% | AI={100*ai_oov_rate:.2f}%\"\n",
    "        )\n",
    "\n",
    "    stats_text = \"\\n\".join(lines)\n",
    "    ax_stats.text(\n",
    "        0.01, 0.95, stats_text,\n",
    "        va=\"top\", ha=\"left\", fontsize=10,\n",
    "        family=\"monospace\",\n",
    "        bbox=dict(boxstyle=\"round,pad=0.4\", alpha=0.10)\n",
    "    )\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_surprisal_histogram(\n",
    "    human_surprisal: np.ndarray,\n",
    "    ai_surprisal: np.ndarray,\n",
    "    bins: int = 40\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Compare surprisal distributions with a cleaner histogram:\n",
    "      - shared bins\n",
    "      - density normalization\n",
    "      - mean markers\n",
    "    \"\"\"\n",
    "    human_surprisal = np.asarray(human_surprisal, dtype=float)\n",
    "    ai_surprisal = np.asarray(ai_surprisal, dtype=float)\n",
    "\n",
    "    h = human_surprisal[np.isfinite(human_surprisal)]\n",
    "    a = ai_surprisal[np.isfinite(ai_surprisal)]\n",
    "\n",
    "    # Shared bins for fair comparison\n",
    "    lo = float(min(np.min(h), np.min(a)))\n",
    "    hi = float(max(np.max(h), np.max(a)))\n",
    "    edges = np.linspace(lo, hi, bins + 1)\n",
    "\n",
    "    plt.figure(figsize=(10, 5), dpi=140)\n",
    "    plt.hist(h, bins=edges, alpha=0.55, density=True, label=\"Human\")\n",
    "    plt.hist(a, bins=edges, alpha=0.55, density=True, label=\"AI\")\n",
    "\n",
    "    # Mean lines (cross-entropy estimate under reference)\n",
    "    h_mean = float(np.mean(h))\n",
    "    a_mean = float(np.mean(a))\n",
    "    plt.axvline(h_mean, linestyle=\"--\", linewidth=1.8, alpha=0.9, label=f\"Human mean: {h_mean:.2f}\")\n",
    "    plt.axvline(a_mean, linestyle=\"--\", linewidth=1.8, alpha=0.9, label=f\"AI mean: {a_mean:.2f}\")\n",
    "\n",
    "    plt.xlabel(\"Surprisal (bits)\")\n",
    "    plt.ylabel(\"Density\")\n",
    "    plt.title(\"Distribution of word surprisal\")\n",
    "    plt.grid(alpha=0.25)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c3125d",
   "metadata": {},
   "source": [
    "## Main Experiment Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88792966",
   "metadata": {},
   "source": [
    "This function is now the main function for our experiment. It will run the following workflow:\n",
    "1. Build reference distribution from human reference corpus\n",
    "2. Score human test and AI test under same reference\n",
    "3. Compute summary statistics\n",
    "4. Build empirical entropy tables for both\n",
    "5. Plot rolling surprisal + histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c98f85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_human_vs_ai_text(\n",
    "        human_reference_text: str,\n",
    "        human_test_text: str,\n",
    "        ai_test_text: str,\n",
    "        alpha: float = 1.0,\n",
    "        base: float = 2.0,\n",
    "        rolling_window: int = 30\n",
    ") -> Dict[str, object]:\n",
    "    \"\"\"\n",
    "    Run the full workflow:\n",
    "      1) Build reference unigram distribution from human reference corpus\n",
    "      2) Score human test and AI test under same reference\n",
    "      3) Compute summary statistics\n",
    "      4) Build empirical entropy tables for both\n",
    "      5) Plot rolling surprisal + histogram\n",
    "\n",
    "    Returns a dictionary with useful outputs (DataFrames, stats, arrays).\n",
    "    \"\"\"\n",
    "\n",
    "    # Reference corpus\n",
    "    ref_tokens = preprocess_text(human_reference_text)\n",
    "    ref_model = ReferenceLanguageModel(ref_tokens, alpha=alpha)\n",
    "\n",
    "    # Score texts\n",
    "    human_tokens, human_surprisal, human_token_df = score_text_with_reference(\n",
    "        human_test_text, ref_model, base=base\n",
    "    )\n",
    "    ai_tokens, ai_surprisal, ai_token_df = score_text_with_reference(\n",
    "        ai_test_text, ref_model, base=base\n",
    "    )\n",
    "\n",
    "    # Summaries\n",
    "    human_summary = summarize_surprisal(human_tokens, human_surprisal)\n",
    "    ai_summary = summarize_surprisal(ai_tokens, ai_surprisal)\n",
    "\n",
    "    summary_df = pd.DataFrame({\n",
    "        \"Human_test\": human_summary,\n",
    "        \"AI_test\": ai_summary    \n",
    "    })\n",
    "\n",
    "    # Entropy tables (empirical, per text)\n",
    "    human_entropy_table, H_human_emp = build_entropy_table(human_tokens, base=base)\n",
    "    ai_entropy_table, H_ai_emp = build_entropy_table(ai_tokens, base=base)\n",
    "\n",
    "    # Add totals to summary\n",
    "    summary_df.loc[\"empirical_entropy_bits_per_token\", \"Human_test\"] = H_human_emp\n",
    "    summary_df.loc[\"empirical_entropy_bits_per_token\", \"AI_test\"] = H_ai_emp\n",
    "\n",
    "    # Cross-entropy quantity (mean surprisal under reference)\n",
    "    summary_df.loc[\"cross_entropy_estimate_bits\", \"Human_test\"] = float(np.mean(human_surprisal))\n",
    "    summary_df.loc[\"cross_entropy_estimate_bits\", \"AI_test\"] = float(np.mean(ai_surprisal))\n",
    "\n",
    "    # Plots\n",
    "    plot_rolling_surprisal(human_surprisal, ai_surprisal, window=rolling_window)\n",
    "    plot_surprisal_histogram(human_surprisal, ai_surprisal, bins=40)\n",
    "\n",
    "    return {\n",
    "        \"summary_df\": summary_df,\n",
    "        \"human_token_df\": human_token_df,\n",
    "        \"ai_token_df\": ai_token_df,\n",
    "        \"human_entropy_table\": human_entropy_table,\n",
    "        \"ai_entropy_table\": ai_entropy_table,\n",
    "        \"human_surprisal\": human_surprisal,\n",
    "        \"ai_surprisal\": ai_surprisal,\n",
    "        \"ref_model\": ref_model,\n",
    "    }\n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebfae407",
   "metadata": {},
   "source": [
    "## The Experiment\n",
    "\n",
    "Let us now run the experiment using three different texts from Lewis Caroll and AI:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35f5f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def read_txt_file(path: str, encoding: str = \"utf-8\") -> str:\n",
    "    path = Path(path)\n",
    "    return path.read_text(encoding=encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3f7795",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "HUMAN_REFERENCE_PATH = \"/Users/fdolci/projects/entropy_lab/data/alice_in_wonderland.txt\"\n",
    "HUMAN_TEST_PATH = \"/Users/fdolci/projects/entropy_lab/data/through_looking_glass_chap2.txt\"\n",
    "AI_TEST_PATH = \"/Users/fdolci/projects/entropy_lab/data/alice_AI.txt\"\n",
    "\n",
    "human_ref_txt = read_txt_file(HUMAN_REFERENCE_PATH)\n",
    "human_test_txt = read_txt_file(HUMAN_TEST_PATH)\n",
    "ai_test_txt = read_txt_file(AI_TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d504a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = compare_human_vs_ai_text(\n",
    "    human_reference_text=human_ref_txt,\n",
    "    human_test_text=human_test_txt,\n",
    "    ai_test_text=ai_test_txt,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda18f25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "entropy_lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
